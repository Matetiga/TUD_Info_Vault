[[Einheit der Entropie]]

Wird auch als *mittlere Unbestimmtheit der Quelle* bezeichnet
$$
H_{i}=\log\left( \frac{1}{p(x_{i})} \right)=-\log(p(x_{i}))
$$
##### $\log_{2}$ wird auch als $ld$ gekennzeichnet
$$
H_{i}=ld\left( \frac{1}{p(x_{i})} \right)=-ld(p(x_{i}))
$$
#### mit: $\lim_{ n \to 0}ld \frac{1}{n}\to 0$

---
## Max. Wert der Entropie
wenn f√ºr alle $i$ folgendes gilt:
$p(x_{i})=\frac{1}{N}$
dann:
$H_{m}$ *Maximal* $= ld (N)$


---
##### [[Mittlere Informationsgehalt]]
