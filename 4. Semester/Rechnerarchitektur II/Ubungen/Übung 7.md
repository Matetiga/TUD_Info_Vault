## 07.1 Vektorrrechnen

### 07.1.2 Speicherverschr√§nkung I
![[Pasted image 20250530175153.png]]

### 07.1.3 Speicherverschr√§nkung II
- Die Daten einer Vektorrechnung werden in physischen separaten Speicherb√§nken gespeichert 

![[Pasted image 20250530175120.png]]

### 07.1.4 Eigenschaften Vektorrechner
![[Pasted image 20250530175230.png]]

---

## 07.2 Arithmetisches Pipelining und Chaining
### 07.2.1 Arithmetische Pipeline Einf√ºhrung
![[Screenshot from 2025-05-30 17-59-27.png]]

### 07.2.2 Arithmetische Pipeline
1. Exponente Vergleichen
2. Mantisse des kleineren Operanden nach rechts verschieben (>>) bis beide Exponenten gleich sind
3. Festkommaaddition der Mantisse 
4. Normalisierung

### 07.2.3 Arithmetische Pipeline Speedup
F√ºr die Laufzeit ohne arithmetisches Pipelining m√ºssen wir die Multiplikationen seriell hintereinander ausf√ºhren, d.h immer eine komplette Multiplikation abwarten und dann erst die n√§chste ansto√üen. Dies ergibt als Formel $ùëõ \cdot ùëò_{ùëöùë¢ùëô}$. Bei einem Vektorrechner m√ºssen wir nur einmalig ein Instruction Fetch, Instruction Decode und Writeback ausf√ºhren, da danach hintereinander ein gleichartiger Befehl, hier die Multiplikation ausgef√ºhrt wird. Folglich haben wir als Gesamtformel ¬†$ùëá_{ohne}=ùëõ \cdot ùëò_{ùëöùë¢ùëô}+ùëõ_{io}$

Mit arithmetischem Pipelining stellen wir in jedem Takt eine Multiplikation fertig, wenn die Pipeline eingelaufen ist. Deshalb ist hier die Formel f√ºr Pipelining in leicht abgewandelter Form anzuwenden, die allgemeine Formel lautet $ùëá=ùëõ+ùëò‚àí1$
Das einzige was hier dazu kommt, sind die 3 Befehle Instruction Fetch, Instruction Decode und Writeback. Der Speedup berechnet sich durch $ùëÜ=\frac{ùëá_{ohne}}{ùëá_{mit}}$

>[!Question]
>Wieso muss man -1 Substrahieren, wenn man arth. Pipelining oder Chaining benutzt

>[!Important]
>Ohne artihmetische Piplining werden alle MUL Operationen nacheinander durchgef√ºhrt. Wenn man das arithmtische Pipelining nimmt, dann werden nur die MUL Operationen (*untereinander im Diagramm*) teilweise Parallel durchgef√ºhrt (**wie treppen** je nach einem Takt)

![[Pasted image 20250531193013.png]]

### 07.2.4 Chaining Einf√ºhrung
- Bei Chaining werden die Ergebnisse nicht zur√ºck in ein Register geschrieben um danach erst wieder von dort geladen zu werden, sondern man gibt das Ergbenis der Multiplikation direkt an die Additionseinheit weiter. Somit fungieren die beiden Operationen, weil direkt aufeinanderfolgend, wie eine zusammenh√§ngende Operation. Deshalb erstzen wir in der Formel k durch $ùëò_{m}+ùëò_{a}$ und betrachten es als eine zusammenh√§ngende Pipeline
![[Pasted image 20250530182748.png]]

### 07.2.5 Chaining Speedup
*Gegeben sei der gleiche Vektorrechner aus Aufgabe "Arithmetische Pipeline Speedup" mit einer Multiplikationseinheit mit 7 Stufen. Die Architektur setzt Vektorregister mit 32 Eintr√§gen um. Die Architektur ben√∂tigt zur Verarbeitung der Befehle zus√§tzlich zur Ausf√ºhrung der arithmetischen Operation die Schritte Instruction Fetch, Instruction Decode und Writeback. Dar√ºber hinaus wird Befehlspipelining und arithmetisches Pipelining unterst√ºtzt.*¬†  
*Zus√§tzlich ist bekannt, dass die Additionseinheit √ºber 5 Stufen verf√ºgt und Chaining unterst√ºtzt wird.*

*Diesmal soll auf 32 Elemente zuerst eine Multiplikation angewendet werden und dann¬†eine Addition.*
![[Pasted image 20250531194355.png]]


---

## 07.3 Leistung 
### 07.3.1 Leistungskurve I
- Die Performance der gesuchten Rechnerart bricht hier immer kurz nach einer fixen Gr√∂√üe und deren Vielfachen ein, woran k√∂nnte das liegen? Welcher Rechner hat ein begrenzten Registersatz und muss danach aus dem Speicher neuladen?

- Vektorregister wird voller mit der Zeit, bis es eine zu voll ist  
![[Screenshot from 2025-05-30 18-38-28.png]]

### 07.3.2 Leistungskurve II
- Hier helfen uns die Anzahl an Puffern, die wir im System haben. Sie bestimmen ma√ügeblich die Kurve mit.
- **Die Kurve f√§llt immer mit der Zeit, da wenn ein Register voll wird, dann wird noch ein anderes Register genutzt aber was langsamer ist** 
![[Pasted image 20250530184024.png]]

### 07.3.3 Leistungskurve III
Bei¬† `steigende`¬†Problemgr√∂√üe sieht man immer wieder Leistungseinbr√ºche. Diese passieren immer dann, wenn die Problemgr√∂√üe N genau `(n*V + 1)` ¬†betr√§gt, also genau `(eins gr√∂√üer ist als)`¬†die L√§nge des Vektorregisters. Das h√§ngt damit zusammen, dass dann f√ºr ein Element nochmal ein komplettes Vektorregister geladen werden muss in dem `(V - 1)` ¬†Pl√§tze nicht belegt sind. Dieser Effekt l√§sst f√ºr `steigende`¬†Problemgr√∂√üen nach, da das Nachladen eines weiteren Vektorregisters `(schw√§cher)` ¬†ins Gewicht f√§llt, je h√§ufiger das Vektorregister insgesamt nachgeladen werden muss

### 07.3.4 Leistungskurve IV
- Die Caches puffern hier unsere Speicherzugriffe, bis diese die Gr√∂√üe des ersten Caches (L1) √ºberschreiten, usw. Also haben wir hier die 3 erkennbaren "Plateaus" in unserer Kurve.
![[Pasted image 20250530184944.png]]


---

## 07.4 SIMD in aktuellen Prozessoren 
### 07.4.1 Einf√ºhrung Berechnung in aktuellen Prozessoren
![[Pasted image 20250601130120.png]]


### 07.4.2 Speedup
- n: Anzahl der Prozesse, die durch die Pipeline laufen
- m: Anzahl der Segmente der Pipeline
- ts: Segmentverarbeitungszeit
- k: (gleichlange) Teilprozesse
	- √ºblicherweise wird die Verarbeitung eines Prozesses durch die Segmente der Pipeline in m (gleichlange) Teilprozesse unterteilt (m = k)
*Nun soll ein Rechner betrachtet werden, der Werte nebenl√§ufig berechnet. F√ºr die Multiplikation werden 7 und die Addition 5 Stufen ben√∂tigt. Die Vektorregister sind 4 Eintr√§ge lang, der gegebene Rechner beherrscht zus√§tzlich arithmetisches Pipelining und es stehen zwei SIMD-Einheiten die vier Multiplikationen bzw. Additionen parallel verarbeiten: jeweils einen Wert des Vektorregisters. Zus√§tzlich gibt es Stufen Instruction Fetch, Instruction Decode und Writeback (IF, ID, WB).*

*Betrachtet werden 32 Elemente, auf die eine Multiplikation gefolgt von einer Addition angewandt werden soll. Dabei gibt es -> Abh√§ngigkeiten zwischen den Daten, sodass die Additionen erst durchgef√ºhrt werden k√∂nnen, nachdem s√§mtliche Multiplikationen berechnet wurden*

F√ºr den Speedup
- $S_{\text{p\_ohne}}=\frac{78}{30}=2.6$

![[Pasted image 20250601125928.png]]


---

## 07.5 Verst√§ndnis
### 07.5.1 Zeitlicher Ablauf I
*Von Takt 9 zu Takt 10 ist gut erkennbar, dass wir ohne Write Back der Multiplikation direkt mit der Addition weiter machen k√∂nnen. Dieses Prinzip haben wir in dieser √úbung bereits kennengelernt. Ein weiterer Hinweis ist, dass wir f√ºr alle Multiplikationen nur genau ein Instruction Fetch und Decode machen m√ºssen.*
![[Pasted image 20250601130322.png]]

### 07.5.2 Zeitlicher Ablauf II
*Hier sieht man deutlich den Unterschied zu der vorherigen Abbildung - wir brauchen f√ºr jeden neuen Block von Multiplikationen/Additionen ein neues Instruction Fetch, Instruction Decode und Writeback. Au√üerdem erkennt man, dass 4 Multiplikationen gleichzeitig ausgef√ºhrt werden k√∂nnen und diese erst nach einem Write Back von der Addition genutzt werden k√∂nnen. Folglich nutzen wir hier eine SIMD-Erweiterung die uns 4 Multiplikationen/Additionen gleichzeitig erm√∂glicht.*
![[Pasted image 20250601130440.png]]

### 07.5.3 Zeitlicher Ablauf III
*In dieser Abbildung sehen wir die √Ñhnlichkeit zur ersten Abbildung (7.5.1). Der einzige Unterschied besteht darin, dass wir hier auf das Write Back der Multiplikation warten m√ºssen, bevor wir mit der Addition anfangen k√∂nnen. Deshalb handelt es sich hier um eine Vektorrechner ohne Chaining.*
- Man erkennt auch die WB der Multiplikation vor dem Beginn der Addition (deswegen auch $n_{io}=4$)

![[Pasted image 20250601130535.png]]



## 07.6
### Encoding auf x86
`MULPS xmm0, [eax]`
- 0F59 (Operation)
- MOD R/M : 00 (*MOD*) 000 (f√ºr *mxx0*) 000 (f√ºr *eax*) ->$00\  000 \ 000_{2}$ = $00_{16}$ (**in hex**)


`VMULPS ymm7, ymm1, [ecx]`
- man nimmt die Operation : 0x <2-Byte VEX> 59
- <0-Byte VEX> : C5
- <1-Byte VEX> : 1($\overline{R}$)  1($\overline{v_{3}}$) 110 ($\overline{v_{3}},\overline{v_{2}},\overline{v_{1}}$) 1 (f√ºr 256-bit) 00 = 1111 0100 = $F4_{16}$
	- man nimmt f√ºr $\overline{v_{3}},\overline{v_{2}},\overline{v_{1}}$ das Invers von 1
- MOD R/M : 00 (Mod) 111 (f√ºr *ymm7*) 001  (f√ºr *ymm1*) = 00 111 001 = $39_{16}$
- Insgesamt : 0x C5 F4 59 39

`VADDPS ymm3, ymm7, ymm5`
-  man nimmt die Operation : 0x <2-Byte VEX> 58
- <0-Byte VEX> : C5
- <1-Byte VEX> : 1($\overline{R}$)  1($\overline{v_{3}}$) 000 ($\overline{v_{3}},\overline{v_{2}},\overline{v_{1}}$) 1 (f√ºr 256-bit) 00 = 1100 0100 = $C4_{16}$
	- man nimmt f√ºr $\overline{v_{3}},\overline{v_{2}},\overline{v_{1}}$ das Invers von 7
- MOD R/M : 11 (Mod) 011 (f√ºr *ymm3*) 101  (f√ºr *ymm5*) = 11 011 101 = $DD_{16}$
- Insgesamt : 0x C5 C4 58 DD


**Sequentiell** 
- (8 Byte (Multiplikation) + 8 Byte (Addtion) ) $\cdot$ 4 (Byte Codel√§nge) = 64 Byte



## 07.7
### Beispiel - Pixel Blending
Um alles sequentiell auszuf√ºhren z√§hlen wir die Anzahl an unterschiedlichen Operationen im gegebenen Code (25 St√ºck). Die einzige Operation, die wir optimieren k√∂nnen, ist `255- x[alpha]`, da diese 4 mal vorkommt. D. h. wir k√∂nnen 3 Operationen davon einsparen. `(25-3=22)`

F√ºr das parallele Verarbeiten teilen wir die Operation in gleichzeitig ausf√ºhrbare Gruppen ein. So k√∂nnen z.B. `x[r]*x[alpha]` parallel mit `x[g]*x[alpha]` und `x[b]*x[alpha]` ausgef√ºhrt werden